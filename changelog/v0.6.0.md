# v0.6.0

Performance, correctness, and concurrency refactor.

## Why

The SSH session mutex was held for the entire channel lifecycle, serializing all commands and defeating SSH2 multiplexing. Single-file sync silently corrupted binary files by routing through UTF-8 string conversion. Auth tried the SSH agent before an explicit identity file, wasting round-trips. Large command output could blow up the LLM context window with no mitigation.

## Changes

### Concurrency
- **Minimized session mutex scope** — lock held only for `channel_open_session()`, then dropped. The returned `Channel` is self-contained, so all subsequent I/O runs without the lock. This enables concurrent SSH commands over the same connection.

```rust
// Before: lock held for entire channel lifecycle
let session = self.session.lock().await;
let mut channel = session.channel_open_session().await?;
channel.exec(true, command).await?;
// ... stdin, stdout collection, close — all under lock

// After: lock only for channel creation
let mut channel = {
    let session = self.session.lock().await;
    session.channel_open_session().await?
};
// Lock dropped — channel operates independently
channel.exec(true, command).await?;
```

### Binary data integrity
- **Added raw byte file operations** — `read_file_raw()` / `write_file_raw()` bypass UTF-8 conversion. Text methods now delegate to these. Single-file sync uses raw bytes, fixing silent binary corruption.

```rust
// Before: sync_push forced UTF-8, corrupting binary files
let content = tokio::fs::read_to_string(local).await?;
conn.write_file(remote_dest, &content).await?;

// After: raw bytes end-to-end
let content = tokio::fs::read(local).await?;
conn.write_file_raw(remote_dest, &content).await?;
```

### Large output handling
- **Save-to-disk for large output** — `remote_bash` saves stdout >128 KB to a local temp file and returns a head/tail summary (first 150 + last 50 lines) with the file path. Full output is always preserved on disk — the LLM gets a scannable summary instead of a context-window bomb.

```rust
const MAX_INLINE_OUTPUT: usize = 128 * 1024;

let stdout = if result.stdout.len() > MAX_INLINE_OUTPUT {
    match save_output_to_disk(&result.stdout).await {
        Ok(path) => build_output_summary(&result.stdout, &path),
        Err(e) => truncate_inline(&result.stdout), // fallback
    }
} else {
    result.stdout
};
```

### Authentication
- **Identity-first auth ordering** — explicit identity file tried before SSH agent (user-specified = highest signal). Avoids wasting auth attempts.
- **Cached RSA hash negotiation** — `best_supported_rsa_hash()` called once before the agent key loop, not once per key. Eliminates N redundant server round-trips.
- **Agent key cap** — limited to 10 keys to avoid "too many authentication failures" from servers that count attempts.

```rust
// Before: query RSA hash for every key (N round-trips)
for key in identities.iter() {
    let hash_alg = rsa_hash_for_key(session, key).await; // server round-trip each time
}

// After: query once, reuse
let cached_rsa_hash = query_rsa_hash(session).await;
for key in identities.iter().take(MAX_AGENT_KEYS) {
    let hash_alg = rsa_hash_for_key(key, &cached_rsa_hash); // pure lookup
}
```

### Connection health
- **Pool auto-removes stale connections** — `pool.get()` checks `is_closed()` on the SSH session. Dead connections are pruned transparently instead of surfacing errors on the next tool call.

```rust
pub async fn get(&self, name: &str) -> Option<Arc<SshConnection>> {
    let conn = {
        let guard = self.connections.read().await;
        guard.get(name).cloned()
    };
    if let Some(ref c) = conn {
        if c.is_closed().await {
            let mut guard = self.connections.write().await;
            guard.remove(name);
            return None;
        }
    }
    conn
}
```

- **Single-lock `list_with_details()`** — `list_servers` handler collects all connection params in one read lock, instead of `list()` + N× `get()`.

### Network efficiency
- **Server-side slicing for `remote_read`** — when offset/limit are specified, uses `sed -n '{start},{end}p'` on the remote instead of transferring the full file and slicing locally.
- **Blocking I/O off tokio runtime** — `walk_dir`, `build_tar_gz`, tar extraction, and `load_secret_key` wrapped in `spawn_blocking`.

### Micro-optimizations
- **Compact JSON** — MCP tool outputs use `to_string` instead of `to_string_pretty`.
- **Single-alloc line formatting** — `format_with_line_numbers` uses `String::with_capacity` + `write!` instead of collect→join.
- **Single-scan remote edit** — replaced `contains()` + `replace()` (two full scans) with one `replacen` + equality check.
